{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c519ad0-6fd8-4adc-93c7-87aeca007484",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a970835-7d3d-448e-b3cf-b6e27af9c4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59bd005c-9bae-4bba-93a5-5fc2b51fae91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors:  94%|█████████████████████████████████████████████████████████▎   | 273M/290M [00:10<00:00, 25.5MB/s]Error while downloading from https://cdn-lfs.huggingface.co/repos/87/ed/87ed574d954a75f12f9f491167f1a0283f7d409293803c435abc7b542c59caa1/d4dd5542fd6a1d35639e21384238f3bfe6c557c849d392b5905d33ee29e71db5?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1702424086&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjQyNDA4Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy84Ny9lZC84N2VkNTc0ZDk1NGE3NWYxMmY5ZjQ5MTE2N2YxYTAyODNmN2Q0MDkyOTM4MDNjNDM1YWJjN2I1NDJjNTljYWExL2Q0ZGQ1NTQyZmQ2YTFkMzU2MzllMjEzODQyMzhmM2JmZTZjNTU3Yzg0OWQzOTJiNTkwNWQzM2VlMjllNzFkYjU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=DjrZuLUxV34mHAR%7E-Fycv-v3l4C5UuHSFGpIJWJR6N2jClUnOgCJrxTu8TcdB8tWX70eCpUe6vbk84%7EZBz9bOpNRJDS86OnmXaXBcpzR-FLcPQ-ifhJFhF9DKPbW0LNAlpeEG-2LyvizVQa%7EmFRrdbF5XkSK4g6fSX7YZxvroMNWuckH4S7EicnegetcuphrbLgbFNAi3EqWH2QRH%7EInX8sMZ7RjSzOXn7bkpe4ygXspnhs8-XuI%7EkvfdC5Kvvq8GG4v0ddIaIy8WEr-OqPY8tjsob0JCsh6eX8Z0LwJo8NZb0TJfR89hhMqqWkuGgSojK80VbRzv-FU6i1A60nyOw__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "\n",
      "model.safetensors:  94%|████████████████████████████████████████████████████████████████▊    | 273M/290M [00:00<?, ?B/s]\u001b[A\n",
      "model.safetensors:  97%|███████████████████████████████████████████████████████████▍ | 283M/290M [00:00<00:00, 17.7MB/s]\u001b[A\n",
      "model.safetensors: 100%|█████████████████████████████████████████████████████████████| 290M/290M [00:01<00:00, 9.82MB/s]\u001b[A\n",
      "model.safetensors:  94%|█████████████████████████████████████████████████████████▎   | 273M/290M [00:25<00:01, 10.8MB/s]\n",
      "generation_config.json: 100%|██████████████████████████████████████████████████████| 1.50k/1.50k [00:00<00:00, 5.30MB/s]\n",
      "tokenizer_config.json: 100%|███████████████████████████████████████████████████████████| 805/805 [00:00<00:00, 3.34MB/s]\n",
      "vocab.json: 100%|████████████████████████████████████████████████████████████████████| 798k/798k [00:00<00:00, 3.04MB/s]\n",
      "tokenizer.json: 100%|██████████████████████████████████████████████████████████████| 2.41M/2.41M [00:00<00:00, 7.33MB/s]\n",
      "merges.txt: 100%|████████████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 3.31MB/s]\n",
      "normalizer.json: 100%|█████████████████████████████████████████████████████████████| 52.7k/52.7k [00:00<00:00, 25.6MB/s]\n",
      "added_tokens.json: 100%|███████████████████████████████████████████████████████████| 34.6k/34.6k [00:00<00:00, 19.2MB/s]\n",
      "special_tokens_map.json: 100%|█████████████████████████████████████████████████████| 1.83k/1.83k [00:00<00:00, 6.85MB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "preprocessor_config.json: 100%|██████████████████████████████████████████████████████| 185k/185k [00:00<00:00, 3.72MB/s]\n"
     ]
    }
   ],
   "source": [
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edffbec5-696c-4d68-9b3d-cc84202c89e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(audio):\n",
    "    sr, y = audio\n",
    "    y = y.astype(np.float32)\n",
    "    y /= np.max(np.abs(y))\n",
    "\n",
    "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b5b4ac2-989c-4e38-b8e2-d6f84c32179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.Interface(\n",
    "    transcribe,\n",
    "    gr.Audio(sources=[\"microphone\"]),\n",
    "    \"text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bfb38ff-3ddd-4c04-9ded-f5de3a805094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/cx/r36_5td907jbsfqm42r03nzw0000gn/T/ipykernel_27947/19592998.py\", line 6, in transcribe\n",
      "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 357, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 1132, in __call__\n",
      "    return next(\n",
      "           ^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n",
      "    item = next(self.iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 266, in __next__\n",
      "    processed = self.infer(next(self.iterator), **self.params)\n",
      "                           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
      "    data.append(next(self.dataset_iter))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 183, in __next__\n",
      "    processed = next(self.subiterator)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 461, in preprocess\n",
      "    raise ImportError(\n",
      "ImportError: torchaudio is required to resample audio samples in AutomaticSpeechRecognitionPipeline. The torchaudio package can be installed through: `pip install torchaudio`.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/cx/r36_5td907jbsfqm42r03nzw0000gn/T/ipykernel_27947/19592998.py\", line 6, in transcribe\n",
      "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 357, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 1132, in __call__\n",
      "    return next(\n",
      "           ^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n",
      "    item = next(self.iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 266, in __next__\n",
      "    processed = self.infer(next(self.iterator), **self.params)\n",
      "                           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
      "    data.append(next(self.dataset_iter))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 183, in __next__\n",
      "    processed = next(self.subiterator)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 461, in preprocess\n",
      "    raise ImportError(\n",
      "ImportError: torchaudio is required to resample audio samples in AutomaticSpeechRecognitionPipeline. The torchaudio package can be installed through: `pip install torchaudio`.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 501, in process_events\n",
      "    response = await self.call_prediction(awake_events, batch)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 465, in call_prediction\n",
      "    raise Exception(str(error) if show_error else None) from error\n",
      "Exception: None\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/cx/r36_5td907jbsfqm42r03nzw0000gn/T/ipykernel_27947/19592998.py\", line 6, in transcribe\n",
      "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 357, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 1132, in __call__\n",
      "    return next(\n",
      "           ^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n",
      "    item = next(self.iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 266, in __next__\n",
      "    processed = self.infer(next(self.iterator), **self.params)\n",
      "                           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
      "    data.append(next(self.dataset_iter))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 183, in __next__\n",
      "    processed = next(self.subiterator)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 461, in preprocess\n",
      "    raise ImportError(\n",
      "ImportError: torchaudio is required to resample audio samples in AutomaticSpeechRecognitionPipeline. The torchaudio package can be installed through: `pip install torchaudio`.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/cx/r36_5td907jbsfqm42r03nzw0000gn/T/ipykernel_27947/19592998.py\", line 6, in transcribe\n",
      "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 357, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 1132, in __call__\n",
      "    return next(\n",
      "           ^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n",
      "    item = next(self.iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 266, in __next__\n",
      "    processed = self.infer(next(self.iterator), **self.params)\n",
      "                           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
      "    data.append(next(self.dataset_iter))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 183, in __next__\n",
      "    processed = next(self.subiterator)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 461, in preprocess\n",
      "    raise ImportError(\n",
      "ImportError: torchaudio is required to resample audio samples in AutomaticSpeechRecognitionPipeline. The torchaudio package can be installed through: `pip install torchaudio`.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 501, in process_events\n",
      "    response = await self.call_prediction(awake_events, batch)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 465, in call_prediction\n",
      "    raise Exception(str(error) if show_error else None) from error\n",
      "Exception: None\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/cx/r36_5td907jbsfqm42r03nzw0000gn/T/ipykernel_27947/19592998.py\", line 6, in transcribe\n",
      "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 357, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 1132, in __call__\n",
      "    return next(\n",
      "           ^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n",
      "    item = next(self.iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 266, in __next__\n",
      "    processed = self.infer(next(self.iterator), **self.params)\n",
      "                           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
      "    data.append(next(self.dataset_iter))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 183, in __next__\n",
      "    processed = next(self.subiterator)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 461, in preprocess\n",
      "    raise ImportError(\n",
      "ImportError: torchaudio is required to resample audio samples in AutomaticSpeechRecognitionPipeline. The torchaudio package can be installed through: `pip install torchaudio`.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/cx/r36_5td907jbsfqm42r03nzw0000gn/T/ipykernel_27947/19592998.py\", line 6, in transcribe\n",
      "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 357, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 1132, in __call__\n",
      "    return next(\n",
      "           ^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n",
      "    item = next(self.iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 266, in __next__\n",
      "    processed = self.infer(next(self.iterator), **self.params)\n",
      "                           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
      "    data.append(next(self.dataset_iter))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 183, in __next__\n",
      "    processed = next(self.subiterator)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 461, in preprocess\n",
      "    raise ImportError(\n",
      "ImportError: torchaudio is required to resample audio samples in AutomaticSpeechRecognitionPipeline. The torchaudio package can be installed through: `pip install torchaudio`.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 501, in process_events\n",
      "    response = await self.call_prediction(awake_events, batch)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 465, in call_prediction\n",
      "    raise Exception(str(error) if show_error else None) from error\n",
      "Exception: None\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/cx/r36_5td907jbsfqm42r03nzw0000gn/T/ipykernel_27947/19592998.py\", line 6, in transcribe\n",
      "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 357, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 1132, in __call__\n",
      "    return next(\n",
      "           ^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n",
      "    item = next(self.iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 266, in __next__\n",
      "    processed = self.infer(next(self.iterator), **self.params)\n",
      "                           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
      "    data.append(next(self.dataset_iter))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 183, in __next__\n",
      "    processed = next(self.subiterator)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 461, in preprocess\n",
      "    raise ImportError(\n",
      "ImportError: torchaudio is required to resample audio samples in AutomaticSpeechRecognitionPipeline. The torchaudio package can be installed through: `pip install torchaudio`.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/cx/r36_5td907jbsfqm42r03nzw0000gn/T/ipykernel_27947/19592998.py\", line 6, in transcribe\n",
      "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 357, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 1132, in __call__\n",
      "    return next(\n",
      "           ^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n",
      "    item = next(self.iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 266, in __next__\n",
      "    processed = self.infer(next(self.iterator), **self.params)\n",
      "                           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
      "    data.append(next(self.dataset_iter))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 183, in __next__\n",
      "    processed = next(self.subiterator)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 461, in preprocess\n",
      "    raise ImportError(\n",
      "ImportError: torchaudio is required to resample audio samples in AutomaticSpeechRecognitionPipeline. The torchaudio package can be installed through: `pip install torchaudio`.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 501, in process_events\n",
      "    response = await self.call_prediction(awake_events, batch)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 465, in call_prediction\n",
      "    raise Exception(str(error) if show_error else None) from error\n",
      "Exception: None\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/cx/r36_5td907jbsfqm42r03nzw0000gn/T/ipykernel_27947/19592998.py\", line 6, in transcribe\n",
      "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 357, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 1132, in __call__\n",
      "    return next(\n",
      "           ^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n",
      "    item = next(self.iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 266, in __next__\n",
      "    processed = self.infer(next(self.iterator), **self.params)\n",
      "                           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
      "    data.append(next(self.dataset_iter))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 183, in __next__\n",
      "    processed = next(self.subiterator)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 461, in preprocess\n",
      "    raise ImportError(\n",
      "ImportError: torchaudio is required to resample audio samples in AutomaticSpeechRecognitionPipeline. The torchaudio package can be installed through: `pip install torchaudio`.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/cx/r36_5td907jbsfqm42r03nzw0000gn/T/ipykernel_27947/19592998.py\", line 6, in transcribe\n",
      "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 357, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 1132, in __call__\n",
      "    return next(\n",
      "           ^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n",
      "    item = next(self.iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 266, in __next__\n",
      "    processed = self.infer(next(self.iterator), **self.params)\n",
      "                           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
      "    data.append(next(self.dataset_iter))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 183, in __next__\n",
      "    processed = next(self.subiterator)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 461, in preprocess\n",
      "    raise ImportError(\n",
      "ImportError: torchaudio is required to resample audio samples in AutomaticSpeechRecognitionPipeline. The torchaudio package can be installed through: `pip install torchaudio`.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 501, in process_events\n",
      "    response = await self.call_prediction(awake_events, batch)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 465, in call_prediction\n",
      "    raise Exception(str(error) if show_error else None) from error\n",
      "Exception: None\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/cx/r36_5td907jbsfqm42r03nzw0000gn/T/ipykernel_27947/19592998.py\", line 6, in transcribe\n",
      "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 357, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 1132, in __call__\n",
      "    return next(\n",
      "           ^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n",
      "    item = next(self.iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 266, in __next__\n",
      "    processed = self.infer(next(self.iterator), **self.params)\n",
      "                           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
      "    data.append(next(self.dataset_iter))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 183, in __next__\n",
      "    processed = next(self.subiterator)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 461, in preprocess\n",
      "    raise ImportError(\n",
      "ImportError: torchaudio is required to resample audio samples in AutomaticSpeechRecognitionPipeline. The torchaudio package can be installed through: `pip install torchaudio`.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/cx/r36_5td907jbsfqm42r03nzw0000gn/T/ipykernel_27947/19592998.py\", line 6, in transcribe\n",
      "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 357, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 1132, in __call__\n",
      "    return next(\n",
      "           ^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n",
      "    item = next(self.iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 266, in __next__\n",
      "    processed = self.infer(next(self.iterator), **self.params)\n",
      "                           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
      "    data.append(next(self.dataset_iter))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py\", line 183, in __next__\n",
      "    processed = next(self.subiterator)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 461, in preprocess\n",
      "    raise ImportError(\n",
      "ImportError: torchaudio is required to resample audio samples in AutomaticSpeechRecognitionPipeline. The torchaudio package can be installed through: `pip install torchaudio`.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 501, in process_events\n",
      "    response = await self.call_prediction(awake_events, batch)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/samitkapadia/Desktop/Fall23/MED-277_Chatbot/med/lib/python3.11/site-packages/gradio/queueing.py\", line 465, in call_prediction\n",
      "    raise Exception(str(error) if show_error else None) from error\n",
      "Exception: None\n"
     ]
    }
   ],
   "source": [
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
